\documentclass[../main.tex]{subfiles}

\begin{document}
    \chapter{Introduction}\label{chap:intro}
    \setcounter{page}{1}

    After many decades of ups and downs, deep learning techniques recently produced unprecedented breakthroughs
    in complex domains like computer vision, speech recognition, and natual language processing. \\
    Deep learning~\cite{deeplearning} is a subset of machine learning based on Artificial Neural Networks---statistical models loosely
    inspired by insights from neuroscience. \\
    Two were the main enablers for this revolution: the ever increasing availability of large labeled
    datasets and the terrific growth of computational power that took place in recent years, in particular
    the advent of GPUs to speed-up by orders of magnitude the kind of computations needed by deep learning.

    \begin{figure}[h!]
        \centering{}
        \includegraphics[width=300px]{img/gpu-vs-cpu.png}
        \caption{GPUs are optimized for parallel tasks, and thus are particularly suited to carry out computations
        like matrix multiplication, which is obiquitous in deep learning.}\label{fig:gpu-vs-cpu}
    \end{figure}

    In computer vision in particular, state-of-the-art approaches for tasks such as image recognition,
    object detection and image segmentation all have Convolutional Neural Networks (CNNs)~\cite{lecun-89e} at their core,
	which are a specialization of the more general feedforward network architecture designed to deal with data characterized
    by a grid-like topology.

    Like the majority of machine learning technologies, also deep learning relies on the i.i.d.\ assumptions, namely
    a set of hypotheses drawn from statistical learning theory~\cite{Vapnik1998} by which the training and the test sets are generated
    from the same data generating process, i.e.\ by the same distribution. \\
    Neural Networks are known for their great generalization capabilities. In fact, when trained on very large
    datasets, such as ImageNet~\cite{imagenet}, CNNs can be used to extract meaningful features from new datasets, on top of which
    a linear classifier (e.g. Linear SVM or Logistic Regression~\cite{fan2008liblinear}) can be successfully trained.
    This method goes under the name of Transfer Learning~\cite{transfer-learning}. \\

    Transfer learning works well when the training and test sets came from very similar distributions. When this condition
    is not met, CNNs tends to perform poorly despite their outstanding generalization capabilities.
    Hence, techniques are needed to deal with such cases. \\
	The problem of dealing with settings in which the i.i.d.\ assumptions
	do not hold is known as Domain Adaptation~\cite{domain-adaptation-review}, in which we seek to minimize generalization error
	in those situations in which there is a significant shift between the training distribution
    (called \textit{source domain} in the domain adaptation terminology) and the test distribution (called \textit{target domain}). \\
    Domain adaptation has important practical consequences, as solving this problem would imply being able to train offline models
    on huge dataset, and have them generalize well when deployed on the real-world.
    A typical scenario is that of a mobile app in which users take photos that are to be analyzed (e.g.\ classified, segmented, \ldots) by
    an algorithm. These pictures are likely to come from a different distribution than that of ImageNet for instance, and also are likely
    to be different between different users.
    The possibility of having a model (trained offline) capable of generalizing to these kinds of situations represents a practical, and
    useful, application of domain adaptation. \\

    This thesis work is about designing techniques to deal with cases in which plain transfer learning does not work well.
	In particular, we focus on those cases where the domain shift is caused by object transformations, such as
    translation and scale. This is because we are mainly interested in robotics applications, in which a robot
    might take pictures from very different angles and viewpoints---a situation which is very different from that of
    the majority of image recognition datasets, in which the object always appears at the center of the image. \\

    The rest of the thesis is organized as follows. After a review of background concepts on domain
    adaptation and deep learning in~\autoref{chap:background}, we review recent literature in~\autoref{chap:related}.
    In~\autoref{chap:approach} we describe our approach, the Domain Multiplicative Fusion (DMF) Network, describing
    the main components and the techniques it builds upon. In~\autoref{chap:experiments} and~\autoref{chap:comparison},
    experiments across a variety of robotics datasets and network architectures are reported.
    The thesis concludes with~\autoref{chap:summary} with a summary and a discussion on future research.

\end{document}
